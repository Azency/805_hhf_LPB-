{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.integrate as spi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "S0 = 1      # 初始资产价格\n",
    "T = 35.0    # 总时长（例如1年）\n",
    "r = 0.06    # 风险无关利率\n",
    "sigma = 0.2 # 波动率\n",
    "dt = 0.01   # 时间步长\n",
    "N = 100     # 总步数\n",
    "g = 0\n",
    "lamda = 1/35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义股价模拟函数\n",
    "def stock_SDE(S0, r, sigma, dt, N, l):\n",
    "    S = np.zeros(N)\n",
    "    S[0] = S0\n",
    "    for t in range(1, N):\n",
    "        Z = np.random.normal(0, 1)\n",
    "        S[t] = S[t-1] * np.exp((r - l - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z)\n",
    "    return S[N-1]\n",
    "\n",
    "# 定义期权收益函数\n",
    "def option_payoff(g, t, S0, r, sigma, dt, N, l):\n",
    "    return max(np.exp(g * t) - stock_SDE(S0, r, sigma, dt, N, l), 0)\n",
    "\n",
    "\n",
    "# 定义单次积分函数\n",
    "def single_V(t, l):\n",
    "    return lamda * np.exp(-lamda * t) * np.exp(-r * t) * option_payoff(g, t, S0, r, sigma, dt, N, l)\n",
    "\n",
    "# 定义费用流函数\n",
    "def fee_flows(l):\n",
    "    return l / (lamda + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# 训练模型\n",
    "M = 100  # 进行多次积分以估算期望\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 随机生成一个 l 值\n",
    "    l_candidate = np.random.uniform(0, 0.001)\n",
    "    \n",
    "    # 估算多次积分的均值\n",
    "    results = []\n",
    "    for _ in range(M):\n",
    "        result, _ = spi.quad(single_V, 0, T, args=(l_candidate,))\n",
    "        results.append(result)\n",
    "    \n",
    "    average_payoff = np.mean(results)\n",
    "    \n",
    "    # 使用神经网络来估计 l\n",
    "    l_pred = model(torch.tensor([[l_candidate]], dtype=torch.float32))\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(l_pred, torch.tensor([[average_payoff]], dtype=torch.float32))\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# 使用训练后的模型来估计最优的 l\n",
    "with torch.no_grad():\n",
    "    l_pred = model(torch.tensor([[0.5]], dtype=torch.float32))\n",
    "    optimal_l = l_pred.item()\n",
    "\n",
    "print(\"Optimal l:\", optimal_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
